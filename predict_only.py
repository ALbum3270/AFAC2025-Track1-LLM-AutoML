#!/usr/bin/env python3
"""
ä»…é¢„æµ‹è„šæœ¬ - åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹å¹¶æ‰§è¡ŒBæ¦œé¢„æµ‹
æ— éœ€é‡æ–°è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime
import warnings
from pathlib import Path
import sys
import os
from typing import Dict

# å¯¼å…¥åŸæœ‰çš„ç±»å’Œå‡½æ•°
from train import Config, EnhancedDataLoader, SuperAdvancedFeatureEngineer, setup_logging, improved_recursive_prediction
from autogluon.tabular import TabularPredictor

warnings.filterwarnings('ignore')

def load_trained_models(config: Config, logger: logging.Logger):
    """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
    models = {}
    
    # åŠ è½½apply_amtæ¨¡å‹
    apply_model_path = "autogluon_models/apply_amt_model"
    if os.path.exists(apply_model_path):
        try:
            models['apply_amt_model'] = TabularPredictor.load(apply_model_path)
            logger.info("âœ… apply_amt æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ apply_amt æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    else:
        logger.error(f"âŒ apply_amt æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {apply_model_path}")
        return None
    
    # åŠ è½½redeem_amtæ¨¡å‹
    redeem_model_path = "autogluon_models/redeem_amt_model"
    if os.path.exists(redeem_model_path):
        try:
            models['redeem_amt_model'] = TabularPredictor.load(redeem_model_path)
            logger.info("âœ… redeem_amt æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ redeem_amt æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    else:
        logger.error(f"âŒ redeem_amt æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {redeem_model_path}")
        return None
    
    return models

def main():
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    logger.info("ğŸš€ å¼€å§‹ä»…é¢„æµ‹æ¨¡å¼ - ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹")
    
    # åŠ è½½é…ç½®
    config = Config()
    
    # 1. åŠ è½½æ•°æ®å’Œç‰¹å¾å·¥ç¨‹
    logger.info("\n==================== æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹ ====================")
    data_loader = EnhancedDataLoader(config, logger)
    df = data_loader.load_data()
    
    # ç‰¹å¾å·¥ç¨‹
    feature_engineer = SuperAdvancedFeatureEngineer(config, logger)
    df = feature_engineer.create_features(df)
    
    logger.info(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°: {df.shape[1]}")
    
    # 2. åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
    logger.info("\n==================== åŠ è½½å·²è®­ç»ƒæ¨¡å‹ ====================")
    models = load_trained_models(config, logger)
    
    if models is None:
        logger.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­é¢„æµ‹")
        return
    
    # 3. å¿«é€Ÿæ¨¡å‹éªŒè¯ï¼ˆå¯é€‰ï¼‰- æš‚æ—¶è·³è¿‡ä»¥é¿å…é‡å¤ä»£ç 
    logger.info("\n==================== æ¨¡å‹éªŒè¯ ====================")
    logger.info("â­ï¸ è·³è¿‡æ¨¡å‹éªŒè¯ï¼Œç›´æ¥è¿›è¡Œé¢„æµ‹ï¼ˆé¿å…ä»£ç é‡å¤ï¼‰")
    
    # 4. Bæ¦œé€’æ¨é¢„æµ‹
    logger.info("\n==================== Bæ¦œé€’æ¨é¢„æµ‹ ====================")
    logger.info("ğŸ¯ å¼€å§‹Bæ¦œæœªæ¥7å¤©é€’æ¨é¢„æµ‹ (v3)")
    
    # åˆ›å»ºæœªæ¥æ—¥æœŸ
    prediction_start = pd.to_datetime(config.PREDICTION_START_DATE)
    future_dates = pd.date_range(start=prediction_start, periods=config.PREDICTION_DAYS, freq='D')
    
    logger.info(f"é¢„æµ‹ç›®æ ‡: {config.PREDICTION_DAYS} å¤©")
    logger.info(f"é¢„æµ‹æ—¥æœŸ: {future_dates[0].date()} åˆ° {future_dates[-1].date()}")
    
    # æ‰§è¡Œé€’æ¨é¢„æµ‹
    try:
        final_predictions = improved_recursive_prediction(df, future_dates, models, config, logger)
        logger.info("âœ… é€’æ¨é¢„æµ‹å®Œæˆ")
        
        # 5. ä¿å­˜é¢„æµ‹ç»“æœ
        logger.info("\n==================== ä¿å­˜é¢„æµ‹ç»“æœ ====================")
        
        # æå–é¢„æµ‹æœŸçš„æ•°æ®
        prediction_results = final_predictions[final_predictions['transaction_date'] >= prediction_start]
        
        # ä¿å­˜è¯¦ç»†é¢„æµ‹ç»“æœ
        output_file = f"Bæ¦œé¢„æµ‹ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        prediction_results.to_csv(output_file, index=False, encoding='utf-8')
        logger.info(f"âœ… è¯¦ç»†é¢„æµ‹ç»“æœå·²ä¿å­˜: {output_file}")
        
        # ä¿å­˜æ¯”èµ›æ ¼å¼ç»“æœ
        competition_format = prediction_results[['fund_code', 'transaction_date', 'apply_amt', 'redeem_amt']].copy()
        competition_format.columns = ['fund_code', 'date', 'apply_amt_pred', 'redeem_amt_pred']
        
        competition_file = f"æ¯”èµ›æäº¤æ ¼å¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        competition_format.to_csv(competition_file, index=False, encoding='utf-8')
        logger.info(f"âœ… æ¯”èµ›æäº¤æ ¼å¼å·²ä¿å­˜: {competition_file}")
        
        # æ‰“å°é¢„æµ‹ç»Ÿè®¡
        logger.info("\n==================== é¢„æµ‹ç»Ÿè®¡ ====================")
        logger.info(f"é¢„æµ‹åŸºé‡‘æ•°é‡: {prediction_results['fund_code'].nunique()}")
        logger.info(f"é¢„æµ‹å¤©æ•°: {prediction_results['transaction_date'].nunique()}")
        logger.info(f"æ€»é¢„æµ‹è®°å½•æ•°: {len(prediction_results)}")
        
        logger.info(f"ç”³è´­é‡‘é¢é¢„æµ‹èŒƒå›´: {prediction_results['apply_amt'].min():.0f} - {prediction_results['apply_amt'].max():.0f}")
        logger.info(f"èµå›é‡‘é¢é¢„æµ‹èŒƒå›´: {prediction_results['redeem_amt'].min():.0f} - {prediction_results['redeem_amt'].max():.0f}")
        
        logger.info("\nğŸ‰ é¢„æµ‹ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ é€’æ¨é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main() 