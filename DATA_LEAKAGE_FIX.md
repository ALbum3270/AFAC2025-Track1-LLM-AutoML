# ğŸš¨ æ•°æ®æ³„éœ²é—®é¢˜ä¿®å¤æŠ¥å‘Š

## é—®é¢˜1ï¼šæœªæ¥é¢„æµ‹é€»è¾‘é”™è¯¯ï¼ˆå·²ä¿®å¤ï¼‰

### âŒ åŸå§‹é”™è¯¯ä»£ç 
```python
# é—®é¢˜ï¼šæ¯ä¸ªæœªæ¥æ—¥æœŸéƒ½å¤åˆ¶ç›¸åŒçš„å†å²æ•°æ®
for fund_code in fund_codes:
    fund_history = df[df['fund_code'] == fund_code].sort_values('transaction_date')
    latest_data = fund_history.iloc[-1].copy()  # åªå¤åˆ¶æœ€æ–°ä¸€å¤©
    
    for future_date in future_dates:
        future_record = latest_data.copy()  # æ¯å¤©éƒ½æ˜¯ç›¸åŒæ•°æ®
        future_record['transaction_date'] = future_date
        future_records.append(future_record)
```

### âœ… ä¿®å¤åä»£ç 
```python
# ä¿®å¤ï¼šä½¿ç”¨é€’æ¨æ–¹å¼ï¼Œé€æ—¥é¢„æµ‹å¹¶æ›´æ–°å†å²æ•°æ®
extended_df = df.copy()

for day_idx, future_date in enumerate(future_dates):
    daily_predictions = []
    
    for fund_code in fund_codes:
        # è·å–åŒ…æ‹¬ä¹‹å‰é¢„æµ‹çš„å®Œæ•´å†å²æ•°æ®
        fund_history = extended_df[extended_df['fund_code'] == fund_code].sort_values('transaction_date')
        
        # åŸºäºå†å²è¶‹åŠ¿å’ŒUVå…³ç³»è¿›è¡Œæ™ºèƒ½é¢„æµ‹
        future_record = predict_next_day(fund_history, future_date)
        daily_predictions.append(future_record)
    
    # å°†å½“æ—¥é¢„æµ‹åŠ å…¥å†å²æ•°æ®ç”¨äºä¸‹ä¸€æ—¥é¢„æµ‹
    extended_df = pd.concat([extended_df, pd.DataFrame(daily_predictions)])
```

### ğŸ¯ ä¿®å¤æ•ˆæœ
- **æ—¶é—´åºåˆ—ç‰¹å¾æœ‰æ•ˆ** - æ»åã€æ»šåŠ¨çª—å£ç‰¹å¾èƒ½æ­£ç¡®åŒºåˆ†ä¸åŒæ—¥æœŸ
- **é€’æ¨é¢„æµ‹åˆç†** - æ¯ä¸€å¤©çš„é¢„æµ‹éƒ½åŸºäºæ›´æ–°åçš„å†å²æ•°æ®
- **ç¬¦åˆå®é™…åœºæ™¯** - æ¨¡æ‹ŸçœŸå®é¢„æµ‹ç¯å¢ƒä¸‹çš„æ•°æ®å¯å¾—æ€§

---

## é—®é¢˜2ï¼šæ¨ªæˆªé¢ç‰¹å¾æ•°æ®æ³„éœ²ï¼ˆå·²ä¿®å¤ï¼‰

### âŒ åŸå§‹é”™è¯¯ä»£ç 
```python
# é—®é¢˜ï¼šä½¿ç”¨åŒæ—¥å…¶ä»–åŸºé‡‘æ•°æ®è®¡ç®—æ’åå’Œå¸‚åœºç»Ÿè®¡
def _add_cross_sectional_features(self, df: pd.DataFrame) -> pd.DataFrame:
    for target_col in self.config.TARGET_COLS:
        # âŒ æ•°æ®æ³„éœ²ï¼šé¢„æµ‹æ—¶æ— æ³•è·å¾—åŒæ—¥å…¶ä»–åŸºé‡‘æ•°æ®
        df[f'{target_col}_daily_rank'] = df.groupby('transaction_date')[target_col].rank(pct=True)
        df[f'{target_col}_daily_zscore'] = df.groupby('transaction_date')[target_col].transform(...)
        
        # âŒ æ•°æ®æ³„éœ²ï¼šä¾èµ–åŒæ—¥å¸‚åœºå¹³å‡
        daily_mean = df.groupby('transaction_date')[target_col].transform('mean')
        df[f'{target_col}_vs_market_mean'] = df[target_col] / daily_mean
```

### âœ… ä¿®å¤åä»£ç 
```python
# ä¿®å¤ï¼šä½¿ç”¨å†å²å¸‚åœºä¿¡æ¯ï¼Œé¿å…å‰ç»æ€§åå·®
def _add_cross_sectional_features(self, df: pd.DataFrame) -> pd.DataFrame:
    for target_col in self.config.TARGET_COLS:
        for date in df['transaction_date'].unique():
            # âœ… åªä½¿ç”¨å†å²æ•°æ®ï¼ˆä¸åŒ…æ‹¬å½“å¤©ï¼‰
            historical_start = current_date - timedelta(days=30)
            historical_end = current_date - timedelta(days=1)
            
            historical_data = df[
                (df['transaction_date'] >= historical_start) & 
                (df['transaction_date'] <= historical_end)
            ][target_col]
            
            # âœ… åŸºäºå†å²åˆ†å¸ƒè®¡ç®—ç›¸å¯¹ä½ç½®
            rank_percentile = (historical_data <= current_value).mean()
            zscore = (current_value - historical_mean) / historical_std
```

### ğŸ¯ ä¿®å¤æ•ˆæœ
- **æ¶ˆé™¤æ•°æ®æ³„éœ²** - åªä½¿ç”¨å†å²å¯å¾—ä¿¡æ¯
- **ä¿æŒç‰¹å¾æ„ä¹‰** - ä»èƒ½åæ˜ ç›¸å¯¹å¸‚åœºä½ç½®
- **ç¬¦åˆé¢„æµ‹ç°å®** - é¢„æµ‹æ—¶ç¡®å®å¯ä»¥è·å¾—è¿™äº›ç‰¹å¾

---

## ğŸ” æ•°æ®æ³„éœ²ç±»å‹æ€»ç»“

### ç±»å‹1ï¼šæ—¶é—´æ³„éœ²ï¼ˆTime Leakageï¼‰
- **é—®é¢˜**ï¼šä½¿ç”¨æœªæ¥ä¿¡æ¯é¢„æµ‹è¿‡å»
- **è¡¨ç°**ï¼šæ‰€æœ‰æœªæ¥æ—¥æœŸä½¿ç”¨ç›¸åŒç‰¹å¾
- **åæœ**ï¼šæ¨¡å‹æ— æ³•åŒºåˆ†ä¸åŒæ—¶é—´ç‚¹

### ç±»å‹2ï¼šåŒæœŸæ³„éœ²ï¼ˆContemporary Leakageï¼‰  
- **é—®é¢˜**ï¼šä½¿ç”¨åŒæœŸå…¶ä»–æ ·æœ¬ä¿¡æ¯
- **è¡¨ç°**ï¼šè®¡ç®—åŒæ—¥æ’åã€å¸‚åœºå¹³å‡ç­‰
- **åæœ**ï¼šé¢„æµ‹æ—¶æ— æ³•è·å¾—è¿™äº›ä¿¡æ¯

### ç±»å‹3ï¼šæœªæ¥ç‰¹å¾æ³„éœ²ï¼ˆFuture Feature Leakageï¼‰
- **é—®é¢˜**ï¼šç‰¹å¾åŒ…å«ç›®æ ‡å˜é‡çš„æœªæ¥ä¿¡æ¯
- **è¡¨ç°**ï¼šç‰¹å¾è®¡ç®—ä¸­ä½¿ç”¨äº†å…¨æ—¶é—´æ®µæ•°æ®
- **åæœ**ï¼šæ¨¡å‹è¡¨ç°è™šé«˜ï¼Œå®é™…éƒ¨ç½²å¤±è´¥

---

## ğŸ›¡ï¸ æ•°æ®æ³„éœ²æ£€éªŒæ–¹æ³•

### 1. æ—¶é—´åºåˆ—æ£€éªŒ
```python
# æ£€æŸ¥ç‰¹å¾æ˜¯å¦éšæ—¶é—´å˜åŒ–
future_features = df[df['transaction_date'] >= prediction_start]
for col in feature_cols:
    variance = future_features.groupby('transaction_date')[col].var()
    if variance.max() == 0:
        print(f"è­¦å‘Šï¼š{col} åœ¨æ‰€æœ‰æœªæ¥æ—¥æœŸéƒ½ç›¸åŒ")
```

### 2. ä¿¡æ¯å¯å¾—æ€§æ£€éªŒ
```python
# æ£€æŸ¥é¢„æµ‹æ—¶æ˜¯å¦èƒ½è·å¾—è¯¥ç‰¹å¾
def check_feature_availability(feature_name, prediction_date):
    """æ£€æŸ¥åœ¨prediction_dateæ—¶æ˜¯å¦èƒ½è®¡ç®—è¯¥ç‰¹å¾"""
    if 'daily_rank' in feature_name:
        return False  # éœ€è¦åŒæ—¥å…¶ä»–åŸºé‡‘æ•°æ®
    if 'market_mean' in feature_name and 'historical' not in feature_name:
        return False  # éœ€è¦åŒæ—¥å¸‚åœºæ•°æ®
    return True
```

### 3. ç‰¹å¾æ—¶æ•ˆæ€§æ£€éªŒ
```python
# æ£€æŸ¥ç‰¹å¾è®¡ç®—çš„æ—¶é—´çª—å£
def validate_time_window(df, feature_col, current_date):
    """éªŒè¯ç‰¹å¾è®¡ç®—åªä½¿ç”¨å†å²æ•°æ®"""
    feature_data = df[df['transaction_date'] < current_date]
    # ç¡®ä¿ç‰¹å¾è®¡ç®—ä¸ä¾èµ–current_dateåŠä¹‹åçš„æ•°æ®
```

---

## ğŸ“Š ä¿®å¤å‰åå¯¹æ¯”

| æ–¹é¢ | ä¿®å¤å‰ | ä¿®å¤å |
|------|--------|--------|
| **æœªæ¥é¢„æµ‹** | æ‰€æœ‰æ—¥æœŸç›¸åŒç‰¹å¾ | é€’æ¨å¼å·®å¼‚åŒ–ç‰¹å¾ |
| **æ¨ªæˆªé¢ç‰¹å¾** | ä½¿ç”¨åŒæ—¥å¸‚åœºæ•°æ® | ä½¿ç”¨å†å²å¸‚åœºæ•°æ® |
| **é¢„æµ‹ç°å®æ€§** | ä¸ç¬¦åˆå®é™…æƒ…å†µ | ç¬¦åˆçœŸå®é¢„æµ‹ç¯å¢ƒ |
| **æ¨¡å‹æ³›åŒ–** | è¿‡æ‹Ÿåˆé£é™©é«˜ | çœŸå®æ³›åŒ–èƒ½åŠ› |
| **ç‰¹å¾æ•°é‡** | åŒæ ·ä¸°å¯Œ | åŒæ ·ä¸°å¯Œ |

---

## ğŸ¯ ä¿®å¤éªŒè¯å»ºè®®

### 1. é‡æ–°è®­ç»ƒæ¨¡å‹
```bash
python train.py  # ä½¿ç”¨ä¿®å¤åçš„ç‰¹å¾å·¥ç¨‹
```

### 2. æ€§èƒ½å¯¹æ¯”
- ä¿®å¤å‰WMAPEå¯èƒ½è™šé«˜
- ä¿®å¤åWMAPEæ˜¯çœŸå®æ¨¡å‹èƒ½åŠ›
- å¦‚æœå·®è·å¾ˆå¤§ï¼Œè¯´æ˜ä¹‹å‰å­˜åœ¨ä¸¥é‡æ•°æ®æ³„éœ²

### 3. ç‰¹å¾é‡è¦æ€§åˆ†æ
```python
# æ£€æŸ¥ä¿®å¤åçš„ç‰¹å¾é‡è¦æ€§
feature_importance = predictor.feature_importance()
print("æ–°çš„é‡è¦ç‰¹å¾æ’åï¼š")
print(feature_importance.head(20))
```

è¿™äº›ä¿®å¤ç¡®ä¿äº†æ¨¡å‹çš„**çœŸå®é¢„æµ‹èƒ½åŠ›**ï¼Œé¿å…äº†åœ¨å®é™…éƒ¨ç½²æ—¶æ€§èƒ½å¤§å¹…ä¸‹é™çš„é£é™©ï¼ 